# ü§ñ VIZZIO AI Assistant - Quick Start

## üöÄ Setup R√°pido (3 passos)

### 1Ô∏è‚É£ Instalar Ollama
```bash
# Windows (escolha uma op√ß√£o)
winget install Ollama.Ollama
# OU baixe em: https://ollama.ai/download
```

### 2Ô∏è‚É£ Instalar modelo recomendado
```bash
# Execute o script de setup (RECOMENDADO)
.\setup-ollama.bat

# OU manualmente:
ollama pull llama3.2:3b
```

### 3Ô∏è‚É£ Rodar a aplica√ß√£o
```bash
.\run.bat
```

Pronto! O AI Assistant ser√° carregado automaticamente se o Ollama estiver dispon√≠vel. ‚úÖ

## üíª Requisitos M√≠nimos

- **RAM**: 8GB (recomendado 16GB)
- **Espa√ßo**: ~2GB para o modelo b√°sico
- **Internet**: Para download inicial do modelo

## üéØ Modelos Dispon√≠veis

### Leves (8GB RAM) ‚≠ê RECOMENDADO
```bash
ollama pull llama3.2:3b    # ~2GB - Balanceado (PADR√ÉO)
ollama pull phi3:mini       # ~2.3GB - Mais r√°pido
```

### M√©dios (16GB RAM)
```bash
ollama pull llama3:8b       # ~4.7GB - Melhor qualidade
ollama pull mistral:7b      # ~4GB - Bom para portugu√™s
```

### Especializados
```bash
ollama pull codellama:7b       # Para an√°lise de c√≥digo
ollama pull llama3-uncensored  # Sem filtros de conte√∫do
```

## üé® Funcionalidades

### ‚úÖ J√° Implementado
- ü§ñ Chat inteligente sobre IFC/BIM
- üîç An√°lise de elementos e propriedades
- üí° Sugest√µes contextuais
- üìö Ajuda sobre recursos do viewer
- üß† Mem√≥ria de conversa√ß√£o
- ‚ö° Respostas em streaming

### üéØ Exemplos de Uso

```csharp
// Criar assistente
var config = AIConfig.LoadFromEnvironment();
using var ollama = new OllamaService(config);
var assistant = new IfcAIAssistant(ollama);

// Fazer perguntas
var help = await assistant.AskAsync("Como usar o modo VR?");

// Analisar elementos
var properties = new Dictionary<string, string>
{
    ["Type"] = "IfcWall",
    ["Height"] = "3.0m"
};
var analysis = await assistant.AnalyzeElementAsync("Wall", properties);

// Obter sugest√µes
var suggestions = await assistant.GetSuggestionsAsync("Modelo grande carregado");
```

## üîß Configura√ß√£o Avan√ßada

### Arquivo `.env`
```env
# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# Outras APIs (opcional)
OPENAI_API_KEY=sua_chave_aqui
DEEPSEEK_API_KEY=sua_chave_aqui
```

### Alterar modelo
Edite o `.env`:
```env
OLLAMA_MODEL=phi3:mini  # Ou qualquer modelo instalado
```

### Ajustar performance
```csharp
var config = new AIConfig
{
    MaxTokens = 1024,      // Reduzir para respostas mais curtas
    Temperature = 0.5f     // 0.0-1.0 (menor = mais conservador)
};
```

## üêõ Solu√ß√£o de Problemas

### ‚ùå "AI Assistant not available"
```bash
# Verificar se Ollama est√° rodando
curl http://localhost:11434/api/tags

# Se n√£o estiver, iniciar:
ollama serve
```

### ‚ùå "Model not found"
```bash
# Listar modelos instalados
ollama list

# Baixar modelo padr√£o
ollama pull llama3.2:3b
```

### ‚ùå Mem√≥ria insuficiente
1. Use modelo menor: `phi3:mini` (2.3GB)
2. Feche outros programas
3. Ajuste `MaxTokens` para 512 ou menos

### ‚ùå Respostas lentas
1. Use GPU se dispon√≠vel (NVIDIA/AMD)
2. Troque para modelo menor
3. Reduza `MaxTokens`

## üìä Performance Esperada

| Modelo | Tamanho | RAM | Velocidade | Qualidade |
|--------|---------|-----|------------|-----------|
| llama3.2:3b | 2GB | 8GB | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê |
| phi3:mini | 2.3GB | 8GB | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê |
| llama3:8b | 4.7GB | 16GB | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| mistral:7b | 4GB | 16GB | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

## üîí Seguran√ßa & Privacidade

- ‚úÖ Roda 100% local (dados n√£o saem da m√°quina)
- ‚úÖ Sem telemetria ou tracking
- ‚úÖ `.env` no `.gitignore` (API keys seguras)
- ‚úÖ C√≥digo open source

## üìö Documenta√ß√£o Completa

Ver: [docs/OLLAMA_SETUP.md](docs/OLLAMA_SETUP.md)

## üÜò Precisa de Ajuda?

1. **Documenta√ß√£o**: [docs/OLLAMA_SETUP.md](docs/OLLAMA_SETUP.md)
2. **Ollama Docs**: https://github.com/ollama/ollama/blob/main/docs/api.md
3. **Issues**: https://github.com/avilaops/vizzio2/issues
4. **Suporte**: https://support.avila.inc

---

**Feito com ‚ù§Ô∏è pela [Avila Development](https://avilaops.com)**
